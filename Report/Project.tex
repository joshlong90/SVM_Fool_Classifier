%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Programming/Coding Assignment
% LaTeX Template
%
% This template has been downloaded from:
% http://www.latextemplates.com
%
% Original author:
% Ted Pavlic (http://www.tedpavlic.com)
%
% Note:
% The \lipsum[#] commands throughout this template generate dummy text
% to fill the template out. These commands should all be removed when 
% writing assignment content.
%
% This template uses a Perl script as an example snippet of code, most other
% languages are also usable. Configure them in the "CODE INCLUSION 
% CONFIGURATION" section.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass{article}

\usepackage{fancyhdr} % Required for custom headers
\usepackage{lastpage} % Required to determine the last page for the footer
\usepackage{extramarks} % Required for headers and footers
\usepackage[usenames,dvipsnames]{color} % Required for custom colors
\usepackage{graphicx} % Required to insert images
\usepackage{listings} % Required for insertion of code
\usepackage{courier} % Required for the courier font
\usepackage{lipsum} % Used for inserting dummy 'Lorem ipsum' text into the template

% Margins
\topmargin=-0.45in
\evensidemargin=0in
\oddsidemargin=0in
\textwidth=6.5in
\textheight=9.0in
\headsep=0.25in

\linespread{1.1} % Line spacing

% Set up the header and footer
\pagestyle{fancy}
\lhead{\hmwkAuthorNameShort} % Top left header
\chead{\hmwkClass:\ \hmwkTitle} % Top center head
\rhead{\firstxmark} % Top right header
%\lfoot{\lastxmark} % Bottom left footer
\cfoot{} % Bottom center footer
\rfoot{Page\ \thepage\ of\ \protect\pageref{LastPage}} % Bottom right footer
\renewcommand\headrulewidth{0.4pt} % Size of the header rule
\renewcommand\footrulewidth{0.4pt} % Size of the footer rule

\setlength\parindent{0pt} % Removes all indentation from paragraphs

%----------------------------------------------------------------------------------------
%	CODE INCLUSION CONFIGURATION
%----------------------------------------------------------------------------------------

\definecolor{MyDarkGreen}{rgb}{0.0,0.4,0.0} % This is the color used for comments
\lstloadlanguages{Perl} % Load Perl syntax for listings, for a list of other languages supported see: ftp://ftp.tex.ac.uk/tex-archive/macros/latex/contrib/listings/listings.pdf
\lstset{language=Perl, % Use Perl in this example
        frame=single, % Single frame around code
        basicstyle=\small\ttfamily, % Use small true type font
        keywordstyle=[1]\color{Blue}\bf, % Perl functions bold and blue
        keywordstyle=[2]\color{Purple}, % Perl function arguments purple
        keywordstyle=[3]\color{Blue}\underbar, % Custom functions underlined and blue
        identifierstyle=, % Nothing special about identifiers                                         
        commentstyle=\usefont{T1}{pcr}{m}{sl}\color{MyDarkGreen}\small, % Comments small dark green courier font
        stringstyle=\color{Purple}, % Strings are purple
        showstringspaces=false, % Don't put marks in string spaces
        tabsize=5, % 5 spaces per tab
        %
        % Put standard Perl functions not included in the default language here
        morekeywords={rand},
        %
        % Put Perl function parameters here
        morekeywords=[2]{on, off, interp},
        %
        % Put user defined functions here
        morekeywords=[3]{test},
       	%
        morecomment=[l][\color{Blue}]{...}, % Line continuation (...) like blue comment
        numbers=left, % Line numbers on left
        firstnumber=1, % Line numbers start with line 1
        numberstyle=\tiny\color{Blue}, % Line numbers are blue and small
        stepnumber=5 % Line numbers go in steps of 5
}

% Creates a new command to include a perl script, the first parameter is the filename of the script (without .pl), the second parameter is the caption
\newcommand{\perlscript}[2]{
\begin{itemize}
\item[]\lstinputlisting[caption=#2,label=#1]{#1.pl}
\end{itemize}
}

%----------------------------------------------------------------------------------------
%	DOCUMENT STRUCTURE COMMANDS
%	Skip this unless you know what you're doing
%----------------------------------------------------------------------------------------

% Header and footer for when a page split occurs within a problem environment
\newcommand{\enterProblemHeader}[1]{
\nobreak\extramarks{#1}{#1 continued on next page\ldots}\nobreak
\nobreak\extramarks{#1 (continued)}{#1 continued on next page\ldots}\nobreak
}

% Header and footer for when a page split occurs between problem environments
\newcommand{\exitProblemHeader}[1]{
\nobreak\extramarks{#1 (continued)}{#1 continued on next page\ldots}\nobreak
\nobreak\extramarks{#1}{}\nobreak
}

\setcounter{secnumdepth}{0} % Removes default section numbers
\newcounter{homeworkProblemCounter} % Creates a counter to keep track of the number of problems

\newcommand{\homeworkProblemName}{}
\newenvironment{homeworkProblem}[1][Problem \arabic{homeworkProblemCounter}]{ % Makes a new environment called homeworkProblem which takes 1 argument (custom name) but the default is "Problem #"
\stepcounter{homeworkProblemCounter} % Increase counter for number of problems
\renewcommand{\homeworkProblemName}{#1} % Assign \homeworkProblemName the name of the problem
\section{\homeworkProblemName} % Make a section in the document with the custom problem count
\enterProblemHeader{\homeworkProblemName} % Header and footer within the environment
}{
\exitProblemHeader{\homeworkProblemName} % Header and footer after the environment
}

\newcommand{\problemAnswer}[1]{ % Defines the problem answer command with the content as the only argument
\noindent\framebox[\columnwidth][c]{\begin{minipage}{0.98\columnwidth}#1\end{minipage}} % Makes the box around the problem answer and puts the content inside
}

\newcommand{\homeworkSectionName}{}
\newenvironment{homeworkSection}[1]{ % New environment for sections within homework problems, takes 1 argument - the name of the section
\renewcommand{\homeworkSectionName}{#1} % Assign \homeworkSectionName to the name of the section from the environment argument
\subsection{\homeworkSectionName} % Make a subsection with the custom name of the subsection
\enterProblemHeader{\homeworkProblemName\ [\homeworkSectionName]} % Header and footer within the environment
}{
\enterProblemHeader{\homeworkProblemName} % Header and footer after the environment
}

%----------------------------------------------------------------------------------------
%	NAME AND CLASS SECTION
%----------------------------------------------------------------------------------------

\newcommand{\hmwkTitle}{Project Report} % Assignment title
\newcommand{\hmwkDueDate}{Sunday,\ May\ 27,\ 2018} % Due date
\newcommand{\hmwkClass}{COMP9318} % Course/class
\newcommand{\hmwkSubject}{Data Warehousing and Data Mining} % Course/class
\newcommand{\hmwkClassTime}{10:30am} % Class/lecture time
\newcommand{\hmwkClassInstructor}{Jones} % Teacher/lecturer
\newcommand{\hmwkAuthorName}{Joshua Long \& Christopher Pollock} % Your name
\newcommand{\hmwkAuthorNameShort}{J. Long \& C. Pollock} % Your name short

%----------------------------------------------------------------------------------------
%	TITLE PAGE
%----------------------------------------------------------------------------------------

\title{
\vspace{3.5in}
\textmd{\textbf{\hmwkSubject}}\\
\textmd{\textbf{\hmwkClass:\ \hmwkTitle}}\\
\normalsize\vspace{0.1in}\small{Due\ on\ \hmwkDueDate}\\
%\vspace{0.1in}\large{\textit{\hmwkClassInstructor\ \hmwkClassTime}}
\vspace{3.5in}
}

\author{\textbf{\hmwkAuthorName}}
\date{} % Insert date here if you want it to appear below your name

%----------------------------------------------------------------------------------------

\begin{document}

\maketitle

%----------------------------------------------------------------------------------------
\textbf{\large Introduction} \\
This report details the process of forming a text modification algorithm designed to fool a target classifier into misclassifying a set of test examples. The provided data for this task contained short paragraphs of text that fall into two classes, class 0 and class 1. The two training files "class-0.txt" and "class-1.txt" provided examples from each of these two classes while the test data file "test\_data.txt" contained class 1 examples only. The purpose of our text modification algorithm was to modify this class 1 test data in order to fool the target classifier into predicting the data as class 0. The exact selection of parameters and other implementation details for the target classifier was not known. This meant there was an element experimentation as well as trial and error in determining the optimal text modification algorithm. \\ \\
\textbf{\large Understanding the Data} \\
The first task in forming our text modification algorithm was to understand the data and work out what the two classes represent. After visual inspection of the two training files "class-0.txt" and "class-1.txt" the data appeared to be indistinguishable to human eyes. \\ \\
In a further attempt to characterise the classes, we ran some tests to find the relative frequency of words in each class. The results did not provide any meaningful information to assist us, at this point we speculated that each class may in fact be slightly different distributions of words that do not fall into any natural categories. \\ \\
\textbf{\large Training a Classifier} \\
After we had investigated the data, our next goal was to train an accurate local classifier to be used for information extraction and local testing. After learning how to implement a SVM classifier using sklearn, we next started running tests on the data with a linear kernel on its default settings. This approach when using all provided training examples proved to not give accuracy any better than chance when tested on the test\_data.txt file. \\ \\
It soon became clear to us that in order to evaluate the accuracy of our classifier, we would need test examples for both class 0 and class 1. Since we were only given a test file for class 1 and we had twice as many training examples for class 0, we used half the examples in "class-0.txt" for training, and the other half for testing. This gave us 180 training examples for each class, 180 test examples for class 0, and 200 test examples for class 1. \\ \\
After further research, we learned about text frequency-inverse document frequency (tf-idf), which improved the classifier. This seemed intuitive at this point as applying tf-idf meant we were assigning much less value to words such as "the" which appear in every training example. By using this term-weighting scheme we were able to achieve accuracy percentages in the high sixties. We now at least knew that there was a detectable statistical difference between the classes, although we still could not determine what they represented. \\ \\
From this point we did some experimentation to improve our classifier accuracy with different kernels and performed a grid search to find optimal parameters. However, this did not yield much improvement. With a linear kernel, we were unable to improve on the default parameters. Our best polynomial kernel was only slightly better.
\newpage
\textbf{\large Fooling the Target Classifier} \\
After training our local classifier, the next task was to find a way to extract useful information from it and utilise this information in our text modification algorithm. The most intuitive approach was to extract feature weights from a linear SVM and use these weights to form a priority structure. We recognised that these weights correspond to the importance the SVM assigns to each feature (word) when predicting the class. A large positive weight means that the word strongly suggests class 1, and a large negative weight strongly suggests class 0. A weight near 0 means that the word has little effect on the classification. \\ \\
After extracting these feature weights we formed a priority structure that would dictate which modifications our algorithm would choose to make. It made sense to place the features in decreasing order of their absolute weight value. Our most successful implementation did this by dividing the features into two groups, one with negative weights associated with class 0 and the other with positive weights associated with class 1. Highest priority for modifications was given to the features at the beginning of each list which contained the most negative or the most positive weights respectively. Our submissions experimented with slight variations on this concept and are detailed below. \\
\\
\textbf{\large Submission 1} \\
Our first idea to fool the target classifier was simply to substitute the 10 words in each example that most strongly suggest class 1 with the 10 words which most strongly suggest class 0. Our algorithm worked like this:
\begin{itemize}
  \item{Train a classifier on the examples in class-0.txt and class-1.txt.}
  \item{Extract the weights that the classifier assigned to each word.}
  \item{Create a list of all the class 0 words, sorted in decreasing order of the absolute value of their weight. i.e. the words that most strongly suggest class 0 are at the start of the list.}
  \item{Create a dictionary mapping each class 1 word to an integer rank. A low rank means high importance, so that when we sort by rank, the most important words come first.}
  \item{For each example in test\_data.txt, find the 10 most important class 1 words and substitute them with the 10 most important class 0 words that are not already present. If the example does not contain 10 class 1 words, add extra words to total 20 changes.}
\end{itemize}
This worked well when tested against our own classifier. We realised that the target classifier would be trained against more examples, and would differ from ours in unknown ways, and would therefore assign different importances to each word. However, we hoped that it would be similar enough for our algorithm to be fairly effective.\\
\\
We did our first submission using this algorithm, and achieved 48\% accuracy. \\
\\
\textbf{\large Submission 2} \\
The next attempt varied from the first by sorting the words into one priority list and selecting the top 20 addition or removal modifications based on the absolute feature weight value. This approach stemmed from the observation that many of the words we were removing in the first submission did not have a high feature weight according to our local classifier. The idea was that it would be more effective to add more class 0 words with high feature weights than remove the weaker class 1 words with low feature weights.
\newpage
The algorithm for our second submission performed as follows:
\begin{itemize}
  \item{Train a classifier on the examples in class-0.txt and class-1.txt.}
  \item{Extract the weights that the classifier assigned to each word.}
  \item{Create a combined list of all the class 0 and class 1 words, sorted in decreasing order of the absolute value of their weight.}
  \item{For each example mark whether a word is present or not. Start at the beginning of the sorted combined list created in the previous step and use the following conditions to decide on a modification.}
  \begin{itemize}
    \item{If the feature is weighted towards class 1 and is present in the example then remove it.}
    \item{If the feature is weighted towards class 0 and is not present in the example then add it.}
    \item{Ignore all other cases and stop once 20 modifications have been made.}
  \end{itemize}
\end{itemize}
The algorithm favoured adding class 0 words since there was typically less than 5 words present in each example with high class 1 feature weights, at least according to our own classifier. This approach looked promising, but when we submitted we only achieved 18\% accuracy. \\
\\
\textbf{\large Submission 3} \\
Our third attempt returned to the word swapping algorithm of our first attempt, but this time we used a TfidfVectorizer with binary=True rather than tf-idf. The resulting accuracy was 33.5\%, worse than our first attempt, so we decided that this was a dead end.\\
\\
\textbf{\large Submission 4} \\
We made a number of changes for our fourth attempt. We noticed that the CountVectorizer removed punctuation, e.g. (mr. changed to mr). Since the word "mr" had a high weight in favour of class 1, we thought it might be better to leave punctuation in place. We read the documentation on CountVectorizer, and learned that you can use a custom tokenizer to change its default behaviour. We modified our code to use a custom tokenizer which only splits on spaces, and does not remove punctuation. Interestingly, this showed that parentheses were one of the most important features for distinguishing the classes. We verified that parentheses are about twice as frequent in class 0 as class 1. This change also improved the accuracy of our own classifier to around 70\%. \\
\\
We also revisited the observation that adding more words than removing had produced poor results, and decided to try only removing words. In some cases our code might not find 20 class 1 words to remove, in which case it would add some class 0 words. When we submitted, our accuracy improved to 92\%. \\
\\
\textbf{\large Submission 5} \\
We next decided to verify whether or not tokens such as "(", ")", and "," really are useful for classification. We modified our algorithm slightly so that it would not consider these tokens for removal. This caused our success rate to fall to 78.5\%, showing that punctuation seems to be one of the important differences between the classes. \\
\\
\textbf{\large Submission 6} \\
Our best results so far had come from only removing words, but we wanted to see if we could find an optimal ratio of removals to additions. We modified our code to remove only 18 words and add 2. This caused our accuracy to drop slightly to 91\%, showing that only removing words is the most effective strategy. \\
\\
At this point we could not think of any plausible ideas to improve our results. For our final assignment submission, we reverted to using the algorithm from submission 4.

%----------------------------------------------------------------------------------------

\end{document}




